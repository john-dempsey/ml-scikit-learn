{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df74f50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed8e1834",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, target = fetch_california_housing(return_X_y=True, as_frame=True)\n",
    "target *= 100  # rescale the target in k$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11ceb7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_boosting = GradientBoostingRegressor(n_estimators=200)\n",
    "cv_results_gbdt = cross_validate(\n",
    "    gradient_boosting,\n",
    "    data,\n",
    "    target,\n",
    "    scoring=\"neg_mean_absolute_error\",\n",
    "    n_jobs=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2b0e57c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Decision Tree\n",
      "Mean absolute error via cross-validation: 46.442 ± 2.915 k$\n",
      "Average fit time: 11.234 seconds\n",
      "Average score time: 0.006 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"Gradient Boosting Decision Tree\")\n",
    "print(\n",
    "    \"Mean absolute error via cross-validation: \"\n",
    "    f\"{-cv_results_gbdt['test_score'].mean():.3f} ± \"\n",
    "    f\"{cv_results_gbdt['test_score'].std():.3f} k$\"\n",
    ")\n",
    "print(f\"Average fit time: {cv_results_gbdt['fit_time'].mean():.3f} seconds\")\n",
    "print(\n",
    "    f\"Average score time: {cv_results_gbdt['score_time'].mean():.3f} seconds\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1814f276",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dempseyj\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:313: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dempseyj\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:313: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 3 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dempseyj\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:313: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 6 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dempseyj\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:313: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 7 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[249.,  39., 231., ...,  83., 162.,  30.],\n",
       "       [248.,  19., 203., ...,  28., 161.,  30.],\n",
       "       [242.,  49., 249., ..., 125., 160.,  29.],\n",
       "       ...,\n",
       "       [ 17.,  15., 126., ...,  49., 200.,  82.],\n",
       "       [ 23.,  16., 136., ...,  29., 200.,  77.],\n",
       "       [ 53.,  14., 130., ...,  93., 199.,  81.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discretizer = KBinsDiscretizer(\n",
    "    n_bins=256, encode=\"ordinal\", strategy=\"quantile\"\n",
    ")\n",
    "data_trans = discretizer.fit_transform(data)\n",
    "data_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66c5126f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[256, 50, 256, 253, 256, 256, 207, 235]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(np.unique(col)) for col in data_trans.T]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33763847",
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_boosting = make_pipeline(\n",
    "    discretizer, GradientBoostingRegressor(n_estimators=200)\n",
    ")\n",
    "cv_results_gbdt = cross_validate(\n",
    "    gradient_boosting,\n",
    "    data,\n",
    "    target,\n",
    "    scoring=\"neg_mean_absolute_error\",\n",
    "    n_jobs=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "295bb9da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Decision Tree with KBinsDiscretizer\n",
      "Mean absolute error via cross-validation: 45.764 ± 2.029 k$\n",
      "Average fit time: 3.405 seconds\n",
      "Average score time: 0.008 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"Gradient Boosting Decision Tree with KBinsDiscretizer\")\n",
    "print(\n",
    "    \"Mean absolute error via cross-validation: \"\n",
    "    f\"{-cv_results_gbdt['test_score'].mean():.3f} ± \"\n",
    "    f\"{cv_results_gbdt['test_score'].std():.3f} k$\"\n",
    ")\n",
    "print(f\"Average fit time: {cv_results_gbdt['fit_time'].mean():.3f} seconds\")\n",
    "print(\n",
    "    f\"Average score time: {cv_results_gbdt['score_time'].mean():.3f} seconds\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "347e9e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram_gradient_boosting = HistGradientBoostingRegressor(\n",
    "    max_iter=200, random_state=0\n",
    ")\n",
    "cv_results_hgbdt = cross_validate(\n",
    "    histogram_gradient_boosting,\n",
    "    data,\n",
    "    target,\n",
    "    scoring=\"neg_mean_absolute_error\",\n",
    "    n_jobs=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d77583a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Histogram Gradient Boosting Decision Tree\n",
      "Mean absolute error via cross-validation: 43.758 ± 2.694 k$\n",
      "Average fit time: 0.816 seconds\n",
      "Average score time: 0.013 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"Histogram Gradient Boosting Decision Tree\")\n",
    "print(\n",
    "    \"Mean absolute error via cross-validation: \"\n",
    "    f\"{-cv_results_hgbdt['test_score'].mean():.3f} ± \"\n",
    "    f\"{cv_results_hgbdt['test_score'].std():.3f} k$\"\n",
    ")\n",
    "print(f\"Average fit time: {cv_results_hgbdt['fit_time'].mean():.3f} seconds\")\n",
    "print(\n",
    "    f\"Average score time: {cv_results_hgbdt['score_time'].mean():.3f} seconds\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
